{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.amp import autocast, GradScaler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.metrics import (mean_squared_error, mean_absolute_error,\n",
    "                             precision_score, recall_score, f1_score, roc_auc_score, jaccard_score)\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Conditional import for U2NET, depending on its location\n",
    "try:\n",
    "    from u2net.u2net import U2NET\n",
    "except ImportError:\n",
    "    from model.u2net.u2net import U2NET\n",
    "\n",
    "# Import EfficientNet only once\n",
    "from efficientnet_pytorch import EfficientNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j4/021_x4956yj27k5fbw31vmp80000gn/T/ipykernel_43477/640893780.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sal_model.load_state_dict(torch.load('u2net/u2net.pth', map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "U2NET(\n",
       "  (stage1): RSU7(\n",
       "    (rebnconvin): REBNCONV(\n",
       "      (conv_s1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv1): REBNCONV(\n",
       "      (conv_s1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (rebnconv2): REBNCONV(\n",
       "      (conv_s1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (rebnconv3): REBNCONV(\n",
       "      (conv_s1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (rebnconv4): REBNCONV(\n",
       "      (conv_s1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (rebnconv5): REBNCONV(\n",
       "      (conv_s1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (rebnconv6): REBNCONV(\n",
       "      (conv_s1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv7): REBNCONV(\n",
       "      (conv_s1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv6d): REBNCONV(\n",
       "      (conv_s1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv5d): REBNCONV(\n",
       "      (conv_s1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv4d): REBNCONV(\n",
       "      (conv_s1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv3d): REBNCONV(\n",
       "      (conv_s1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv2d): REBNCONV(\n",
       "      (conv_s1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv1d): REBNCONV(\n",
       "      (conv_s1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (pool12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (stage2): RSU6(\n",
       "    (rebnconvin): REBNCONV(\n",
       "      (conv_s1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv1): REBNCONV(\n",
       "      (conv_s1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (rebnconv2): REBNCONV(\n",
       "      (conv_s1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (rebnconv3): REBNCONV(\n",
       "      (conv_s1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (rebnconv4): REBNCONV(\n",
       "      (conv_s1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (rebnconv5): REBNCONV(\n",
       "      (conv_s1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv6): REBNCONV(\n",
       "      (conv_s1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv5d): REBNCONV(\n",
       "      (conv_s1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv4d): REBNCONV(\n",
       "      (conv_s1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv3d): REBNCONV(\n",
       "      (conv_s1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv2d): REBNCONV(\n",
       "      (conv_s1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv1d): REBNCONV(\n",
       "      (conv_s1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (pool23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (stage3): RSU5(\n",
       "    (rebnconvin): REBNCONV(\n",
       "      (conv_s1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv1): REBNCONV(\n",
       "      (conv_s1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (rebnconv2): REBNCONV(\n",
       "      (conv_s1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (rebnconv3): REBNCONV(\n",
       "      (conv_s1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (rebnconv4): REBNCONV(\n",
       "      (conv_s1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv5): REBNCONV(\n",
       "      (conv_s1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv4d): REBNCONV(\n",
       "      (conv_s1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv3d): REBNCONV(\n",
       "      (conv_s1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv2d): REBNCONV(\n",
       "      (conv_s1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv1d): REBNCONV(\n",
       "      (conv_s1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (pool34): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (stage4): RSU4(\n",
       "    (rebnconvin): REBNCONV(\n",
       "      (conv_s1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv1): REBNCONV(\n",
       "      (conv_s1): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (rebnconv2): REBNCONV(\n",
       "      (conv_s1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (rebnconv3): REBNCONV(\n",
       "      (conv_s1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv4): REBNCONV(\n",
       "      (conv_s1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv3d): REBNCONV(\n",
       "      (conv_s1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv2d): REBNCONV(\n",
       "      (conv_s1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv1d): REBNCONV(\n",
       "      (conv_s1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (pool45): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (stage5): RSU4F(\n",
       "    (rebnconvin): REBNCONV(\n",
       "      (conv_s1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv1): REBNCONV(\n",
       "      (conv_s1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv2): REBNCONV(\n",
       "      (conv_s1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv3): REBNCONV(\n",
       "      (conv_s1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
       "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv4): REBNCONV(\n",
       "      (conv_s1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8))\n",
       "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv3d): REBNCONV(\n",
       "      (conv_s1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
       "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv2d): REBNCONV(\n",
       "      (conv_s1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv1d): REBNCONV(\n",
       "      (conv_s1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (pool56): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (stage6): RSU4F(\n",
       "    (rebnconvin): REBNCONV(\n",
       "      (conv_s1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv1): REBNCONV(\n",
       "      (conv_s1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv2): REBNCONV(\n",
       "      (conv_s1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv3): REBNCONV(\n",
       "      (conv_s1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
       "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv4): REBNCONV(\n",
       "      (conv_s1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8))\n",
       "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv3d): REBNCONV(\n",
       "      (conv_s1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
       "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv2d): REBNCONV(\n",
       "      (conv_s1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv1d): REBNCONV(\n",
       "      (conv_s1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (stage5d): RSU4F(\n",
       "    (rebnconvin): REBNCONV(\n",
       "      (conv_s1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv1): REBNCONV(\n",
       "      (conv_s1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv2): REBNCONV(\n",
       "      (conv_s1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv3): REBNCONV(\n",
       "      (conv_s1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
       "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv4): REBNCONV(\n",
       "      (conv_s1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8))\n",
       "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv3d): REBNCONV(\n",
       "      (conv_s1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
       "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv2d): REBNCONV(\n",
       "      (conv_s1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv1d): REBNCONV(\n",
       "      (conv_s1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (stage4d): RSU4(\n",
       "    (rebnconvin): REBNCONV(\n",
       "      (conv_s1): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv1): REBNCONV(\n",
       "      (conv_s1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (rebnconv2): REBNCONV(\n",
       "      (conv_s1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (rebnconv3): REBNCONV(\n",
       "      (conv_s1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv4): REBNCONV(\n",
       "      (conv_s1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv3d): REBNCONV(\n",
       "      (conv_s1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv2d): REBNCONV(\n",
       "      (conv_s1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv1d): REBNCONV(\n",
       "      (conv_s1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (stage3d): RSU5(\n",
       "    (rebnconvin): REBNCONV(\n",
       "      (conv_s1): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv1): REBNCONV(\n",
       "      (conv_s1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (rebnconv2): REBNCONV(\n",
       "      (conv_s1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (rebnconv3): REBNCONV(\n",
       "      (conv_s1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (rebnconv4): REBNCONV(\n",
       "      (conv_s1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv5): REBNCONV(\n",
       "      (conv_s1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv4d): REBNCONV(\n",
       "      (conv_s1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv3d): REBNCONV(\n",
       "      (conv_s1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv2d): REBNCONV(\n",
       "      (conv_s1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv1d): REBNCONV(\n",
       "      (conv_s1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (stage2d): RSU6(\n",
       "    (rebnconvin): REBNCONV(\n",
       "      (conv_s1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv1): REBNCONV(\n",
       "      (conv_s1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (rebnconv2): REBNCONV(\n",
       "      (conv_s1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (rebnconv3): REBNCONV(\n",
       "      (conv_s1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (rebnconv4): REBNCONV(\n",
       "      (conv_s1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (rebnconv5): REBNCONV(\n",
       "      (conv_s1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv6): REBNCONV(\n",
       "      (conv_s1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv5d): REBNCONV(\n",
       "      (conv_s1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv4d): REBNCONV(\n",
       "      (conv_s1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv3d): REBNCONV(\n",
       "      (conv_s1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv2d): REBNCONV(\n",
       "      (conv_s1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv1d): REBNCONV(\n",
       "      (conv_s1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (stage1d): RSU7(\n",
       "    (rebnconvin): REBNCONV(\n",
       "      (conv_s1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv1): REBNCONV(\n",
       "      (conv_s1): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (rebnconv2): REBNCONV(\n",
       "      (conv_s1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (rebnconv3): REBNCONV(\n",
       "      (conv_s1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (rebnconv4): REBNCONV(\n",
       "      (conv_s1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (rebnconv5): REBNCONV(\n",
       "      (conv_s1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (rebnconv6): REBNCONV(\n",
       "      (conv_s1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv7): REBNCONV(\n",
       "      (conv_s1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv6d): REBNCONV(\n",
       "      (conv_s1): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv5d): REBNCONV(\n",
       "      (conv_s1): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv4d): REBNCONV(\n",
       "      (conv_s1): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv3d): REBNCONV(\n",
       "      (conv_s1): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv2d): REBNCONV(\n",
       "      (conv_s1): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "    (rebnconv1d): REBNCONV(\n",
       "      (conv_s1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu_s1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (side1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (side2): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (side3): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (side4): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (side5): Conv2d(512, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (side6): Conv2d(512, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (outconv): Conv2d(6, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "sal_model = U2NET(3, 1).to(device)\n",
    "sal_model.load_state_dict(torch.load('u2net/u2net.pth', map_location=device))\n",
    "sal_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_saliency_mask(image_path, model, device):\n",
    "    \"\"\"\n",
    "    Generates a saliency mask for the given image using U^2-Net.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the image file.\n",
    "        model (torch.nn.Module): Pre-trained saliency detection model.\n",
    "        device (torch.device): Device to perform computation on.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Saliency mask normalized between 0 and 1.\n",
    "    \"\"\"\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((320, 320)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        d1, d2, d3, d4, d5, d6, d7 = model(input_tensor)\n",
    "        pred = d1[:, 0, :, :]\n",
    "        pred = pred.cpu().numpy()  # Shape: (1, H, W)\n",
    "        pred = pred.squeeze(0)      # Now pred has shape (H, W)\n",
    "        pred = (pred - pred.min()) / (pred.max() - pred.min() + 1e-8)  # Normalize to [0,1]\n",
    "        pred = np.uint8(pred * 255)\n",
    "        pred = Image.fromarray(pred).resize(image.size, resample=Image.BILINEAR)\n",
    "        pred = np.array(pred) / 255.0  # Normalize to [0,1]\n",
    "    \n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KonIQ10kDataset(Dataset):\n",
    "    def __init__(self, images_dir, csv_file, saliency_model, device, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            images_dir (str): Path to images.\n",
    "            csv_file (str): Path to the CSV file with global scores.\n",
    "            saliency_model (torch.nn.Module): Pre-trained saliency detection model.\n",
    "            device (torch.device): Device to perform computation on.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.images_dir = images_dir\n",
    "        self.global_scores = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.saliency_model = saliency_model\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.global_scores)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get image filename and global score\n",
    "        img_name = self.global_scores.iloc[idx, 0]\n",
    "        score = self.global_scores.iloc[idx, 1]\n",
    "        \n",
    "        # Load image\n",
    "        img_path = os.path.join(self.images_dir, img_name)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        image_np = np.array(image)\n",
    "        \n",
    "        # Generate saliency mask\n",
    "        saliency_mask = generate_saliency_mask(img_path, self.saliency_model, self.device)\n",
    "        saliency_mask = np.expand_dims(saliency_mask, axis=-1)  # Add channel dimension\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image_np, mask=saliency_mask)\n",
    "            image = augmented['image']\n",
    "            saliency_mask = augmented['mask']\n",
    "        \n",
    "        # Convert mask to binary (threshold can be adjusted)\n",
    "        saliency_mask = (saliency_mask > 0.5).float()\n",
    "        \n",
    "        return image, torch.tensor(score, dtype=torch.float32), saliency_mask.squeeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_transforms(train=True):\n",
    "    if train:\n",
    "        return A.Compose([\n",
    "            A.Resize(224, 224),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.RandomBrightnessContrast(p=0.2),\n",
    "            A.Rotate(limit=15, p=0.3),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                        std=(0.229, 0.224, 0.225)),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "    else:\n",
    "        return A.Compose([\n",
    "            A.Resize(224, 224),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                        std=(0.229, 0.224, 0.225)),\n",
    "            ToTensorV2(),\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "images_dir = '../koniq-10k/images/'  # Update with your actual path\n",
    "csv_file = '../koniq-10k/annotations/koniq-10k.csv'  # Update with your actual path\n",
    "batch_size = 16\n",
    "validation_split = 0.2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "\n",
    "# Initialize the dataset\n",
    "full_dataset = KonIQ10kDataset(images_dir, csv_file, saliency_model=sal_model, device=device, transform=get_transforms(train=True))\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(full_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "valid_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = DataLoader(full_dataset, batch_size=batch_size, sampler=train_sampler, num_workers=0)\n",
    "valid_loader = DataLoader(full_dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetIQA(nn.Module):\n",
    "    def __init__(self, efficientnet_version='efficientnet-b0', pretrained=True):\n",
    "        super(EfficientNetIQA, self).__init__()\n",
    "        # Load EfficientNet backbone\n",
    "        self.backbone = EfficientNet.from_pretrained(efficientnet_version) if pretrained else EfficientNet.from_name(efficientnet_version)\n",
    "        \n",
    "        # Remove the classification head\n",
    "        self.backbone._fc = nn.Identity()\n",
    "        self.backbone._avg_pooling = nn.Identity()\n",
    "        \n",
    "        # Global Quality Assessment Head\n",
    "        self.global_head = nn.Sequential(\n",
    "            nn.Linear(1280, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 1)  # Regression output\n",
    "        )\n",
    "        \n",
    "        # Local Quality Assessment Head\n",
    "        # We'll add convolutional layers to generate a quality map\n",
    "        self.local_head = nn.Sequential(\n",
    "            nn.Conv2d(1280, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.Conv2d(512, 1, kernel_size=1),\n",
    "            nn.Sigmoid()  # Output between 0 and 1\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass through EfficientNet backbone\n",
    "        features = self.backbone.extract_features(x)  # Shape: [B, 1280, H, W]\n",
    "        \n",
    "        # Global Quality\n",
    "        # Adaptive pooling to get a fixed-size feature vector\n",
    "        pooled = F.adaptive_avg_pool2d(features, (1,1)).view(features.size(0), -1)  # Shape: [B, 1280]\n",
    "        global_quality = self.global_head(pooled).squeeze(1)  # Shape: [B]\n",
    "        \n",
    "        # Local Quality\n",
    "        local_quality_map = self.local_head(features)  # Shape: [B, 1, H, W]\n",
    "        local_quality_map = F.interpolate(\n",
    "            local_quality_map,\n",
    "            size=(x.size(2), x.size(3)),  # Ensure size is a tuple (height, width)\n",
    "            mode='bilinear',\n",
    "            align_corners=False\n",
    "        )  # Resizes to [B, 1, H_in, W_in]\n",
    "        local_quality_map = local_quality_map.squeeze(1)  # Now shape is [B, H_in, W_in]\n",
    "        \n",
    "        return global_quality, local_quality_map\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize the model\n",
    "model = EfficientNetIQA().to(device)\n",
    "\n",
    "# Define loss functions\n",
    "criterion_global = nn.MSELoss()\n",
    "criterion_local = nn.BCELoss()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Optionally, define a learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/columbia/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/var/folders/j4/021_x4956yj27k5fbw31vmp80000gn/T/ipykernel_29978/1323169565.py:24: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/opt/anaconda3/envs/columbia/lib/python3.9/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/30]:   0%|          | 0/504 [00:00<?, ?it/s]/Users/luigiliu/Desktop/Columbia/DL for CV 4995/Final project/model/u2net/u2net.py:23: UserWarning: `nn.functional.upsample` is deprecated. Use `nn.functional.interpolate` instead.\n",
      "  src = F.upsample(src,size=tar.shape[2:],mode='bilinear')\n",
      "/var/folders/j4/021_x4956yj27k5fbw31vmp80000gn/T/ipykernel_29978/1323169565.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/opt/anaconda3/envs/columbia/lib/python3.9/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Epoch [1/30]:  48%|     | 241/504 [16:56<17:44,  4.05s/it, global_loss=0.0274, local_loss=0.706, loss=0.733] "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Parameters\n",
    "num_epochs = 30\n",
    "alpha = 1.0  # Weight for global loss\n",
    "beta = 1.0   # Weight for local loss\n",
    "\n",
    "# Initialize optimizer and other components (Assuming they are already defined)\n",
    "# optimizer = ...\n",
    "# criterion_global = ...\n",
    "# criterion_local = ...\n",
    "\n",
    "# Define scheduler after optimizer is defined\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "patience = 10\n",
    "\n",
    "# Initialize GradScaler for mixed precision\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Move model to device before starting training\n",
    "model = EfficientNetIQA().to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_global_loss = 0.0\n",
    "    running_local_loss = 0.0\n",
    "    \n",
    "    loop = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "    for images, scores, masks in loop:\n",
    "        # Move data to the appropriate device\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        scores = scores.to(device, non_blocking=True)\n",
    "        masks = masks.to(device, non_blocking=True)\n",
    "        \n",
    "        if masks.dim() == 4 and masks.size(-1) == 1:\n",
    "            masks = masks.squeeze(-1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast():\n",
    "            # Forward pass\n",
    "            outputs_global, outputs_local = model(images)\n",
    "            \n",
    "            # Compute losses\n",
    "            loss_global = criterion_global(outputs_global, scores)\n",
    "            loss_local = criterion_local(outputs_local, masks)\n",
    "            loss = alpha * loss_global + beta * loss_local\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        # Update running losses\n",
    "        running_loss += loss.item()\n",
    "        running_global_loss += loss_global.item()\n",
    "        running_local_loss += loss_local.item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        loop.set_postfix(loss=loss.item(), global_loss=loss_global.item(), local_loss=loss_local.item())\n",
    "    \n",
    "    # Validation after each epoch\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_global_loss = 0.0\n",
    "    val_local_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, scores, masks in valid_loader:\n",
    "            # Move data to the appropriate device\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            scores = scores.to(device, non_blocking=True)\n",
    "            masks = masks.to(device, non_blocking=True)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs_global, outputs_local = model(images)\n",
    "            \n",
    "            # Compute losses\n",
    "            loss_global = criterion_global(outputs_global, scores)\n",
    "            loss_local = criterion_local(outputs_local, masks)\n",
    "            loss = alpha * loss_global + beta * loss_local\n",
    "            \n",
    "            # Accumulate validation losses\n",
    "            val_loss += loss.item()\n",
    "            val_global_loss += loss_global.item()\n",
    "            val_local_loss += loss_local.item()\n",
    "    \n",
    "    # Calculate average losses\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    avg_train_global_loss = running_global_loss / len(train_loader)\n",
    "    avg_train_local_loss = running_local_loss / len(train_loader)\n",
    "    avg_val_loss = val_loss / len(valid_loader)\n",
    "    avg_val_global_loss = val_global_loss / len(valid_loader)\n",
    "    avg_val_local_loss = val_local_loss / len(valid_loader)\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f} | Global: {avg_train_global_loss:.4f} | Local: {avg_train_local_loss:.4f}\")\n",
    "    print(f\"Val Loss: {avg_val_loss:.4f} | Global: {avg_val_global_loss:.4f} | Local: {avg_val_local_loss:.4f}\")\n",
    "    \n",
    "    # Scheduler step after validation\n",
    "    scheduler.step(avg_val_loss)\n",
    "    \n",
    "    # Early Stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        # Save the best model\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "    \n",
    "    # Optionally, save model checkpoints\n",
    "    torch.save(model.state_dict(), f'checkpoint_epoch_{epoch+1}.pth')\n",
    "\n",
    "# Load the best model after training\n",
    "model = EfficientNetIQA().to(device)\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luigiliu/Desktop/Columbia/DL for CV 4995/Final project/model/u2net/u2net.py:23: UserWarning: `nn.functional.upsample` is deprecated. Use `nn.functional.interpolate` instead.\n",
      "  src = F.upsample(src,size=tar.shape[2:],mode='bilinear')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Quality Assessment Metrics:\n",
      "MSE: 0.0132\n",
      "MAE: 0.0784\n",
      "Pearson Correlation: 0.0445\n",
      "Spearman Correlation: 0.0836\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. None expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m recall \u001b[38;5;241m=\u001b[39m recall_score(all_targets_local_bin_flat, all_preds_local_bin_flat)\n\u001b[1;32m     49\u001b[0m f1 \u001b[38;5;241m=\u001b[39m f1_score(all_targets_local_bin_flat, all_preds_local_bin_flat)\n\u001b[0;32m---> 50\u001b[0m auc \u001b[38;5;241m=\u001b[39m \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_targets_local_bin_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_preds_local\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mLocal Quality Assessment Metrics:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIoU: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00miou\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/columbia/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/columbia/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:619\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    617\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    618\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 619\u001b[0m y_score \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    622\u001b[0m     y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y_score\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y_score\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    623\u001b[0m ):\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;66;03m# do not support partial ROC computation for multiclass\u001b[39;00m\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m max_fpr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m max_fpr \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/columbia/lib/python3.9/site-packages/sklearn/utils/validation.py:1058\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1054\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1055\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1056\u001b[0m     )\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nd \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m-> 1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1061\u001b[0m     )\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m   1064\u001b[0m     _assert_all_finite(\n\u001b[1;32m   1065\u001b[0m         array,\n\u001b[1;32m   1066\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m   1067\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m   1068\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1069\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with dim 3. None expected <= 2."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model.eval()\n",
    "all_scores = []\n",
    "all_preds_global = []\n",
    "all_targets_global = []\n",
    "all_preds_local = []\n",
    "all_targets_local = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, scores, masks in valid_loader:\n",
    "        images = images.to(device)\n",
    "        scores = scores.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        outputs_global, outputs_local = model(images)\n",
    "        \n",
    "        # Collect global scores\n",
    "        all_preds_global.extend(outputs_global.cpu().numpy())\n",
    "        all_targets_global.extend(scores.cpu().numpy())\n",
    "        \n",
    "        # Collect local masks\n",
    "        all_preds_local.extend(outputs_local.cpu().numpy())\n",
    "        all_targets_local.extend(masks.cpu().numpy())\n",
    "\n",
    "# Global Metrics\n",
    "mse = mean_squared_error(all_targets_global, all_preds_global)\n",
    "mae = mean_absolute_error(all_targets_global, all_preds_global)\n",
    "pearson_corr, _ = pearsonr(all_targets_global, all_preds_global)\n",
    "spearman_corr, _ = spearmanr(all_targets_global, all_preds_global)\n",
    "\n",
    "print(\"Global Quality Assessment Metrics:\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"Pearson Correlation: {pearson_corr:.4f}\")\n",
    "print(f\"Spearman Correlation: {spearman_corr:.4f}\")\n",
    "\n",
    "# Local Metrics\n",
    "# Binarize predictions with a threshold (e.g., 0.5)\n",
    "threshold = 0.5\n",
    "all_preds_local_bin = (np.array(all_preds_local) > threshold).astype(int)\n",
    "all_targets_local_bin = (np.array(all_targets_local) > 0.5).astype(int)\n",
    "\n",
    "# Flatten the masks for metric computation\n",
    "all_preds_local_bin_flat = all_preds_local_bin.flatten()\n",
    "all_targets_local_bin_flat = all_targets_local_bin.flatten()\n",
    "\n",
    "iou = jaccard_score(all_targets_local_bin_flat, all_preds_local_bin_flat)\n",
    "precision = precision_score(all_targets_local_bin_flat, all_preds_local_bin_flat)\n",
    "recall = recall_score(all_targets_local_bin_flat, all_preds_local_bin_flat)\n",
    "f1 = f1_score(all_targets_local_bin_flat, all_preds_local_bin_flat)\n",
    "auc = roc_auc_score(all_targets_local_bin_flat, np.array(all_preds_local))\n",
    "\n",
    "print(\"\\nLocal Quality Assessment Metrics:\")\n",
    "print(f\"IoU: {iou:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(f\"AUC: {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def visualize_quality_maps(model, dataset, device, num_samples=5):\n",
    "    model.eval()\n",
    "    indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx in indices:\n",
    "            image, score, mask = dataset[idx]\n",
    "            input_image = image.unsqueeze(0).to(device)\n",
    "            pred_global, pred_local = model(input_image)\n",
    "            pred_global = pred_global.item()\n",
    "            pred_local = pred_local.squeeze().cpu().numpy()\n",
    "            \n",
    "            # Threshold the local quality map\n",
    "            pred_local_bin = (pred_local > 0.5).astype(int)\n",
    "            \n",
    "            # Original image\n",
    "            img = image.permute(1, 2, 0).cpu().numpy()\n",
    "            img = np.clip(img * np.array([0.229, 0.224, 0.225]) + \n",
    "                          np.array([0.485, 0.456, 0.406]), 0, 1)\n",
    "            \n",
    "            # Ground truth mask\n",
    "            gt_mask = mask.cpu().numpy()\n",
    "            \n",
    "            # Plotting\n",
    "            fig, axs = plt.subplots(1, 3, figsize=(15,5))\n",
    "            axs[0].imshow(img)\n",
    "            axs[0].set_title(f\"Original Image\\nGlobal Score: {score:.2f}\")\n",
    "            axs[0].axis('off')\n",
    "            \n",
    "            axs[1].imshow(img)\n",
    "            axs[1].imshow(gt_mask, alpha=0.5, cmap='jet')\n",
    "            axs[1].set_title(\"Ground Truth Quality Map\")\n",
    "            axs[1].axis('off')\n",
    "            \n",
    "            axs[2].imshow(img)\n",
    "            axs[2].imshow(pred_local, alpha=0.5, cmap='jet')\n",
    "            axs[2].set_title(f\"Predicted Quality Map\\nGlobal Score: {pred_global:.2f}\")\n",
    "            axs[2].axis('off')\n",
    "            \n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_heatmap(model, dataset, device, num_samples=5):\n",
    "    model.eval()\n",
    "    indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx in indices:\n",
    "            image, score, mask = dataset[idx]\n",
    "            input_image = image.unsqueeze(0).to(device)\n",
    "            pred_global, pred_local = model(input_image)\n",
    "            pred_global = pred_global.item()\n",
    "            pred_local = pred_local.squeeze().cpu().numpy()\n",
    "            \n",
    "            # Normalize the quality map for better visualization\n",
    "            pred_local_norm = (pred_local - pred_local.min()) / (pred_local.max() - pred_local.min() + 1e-8)\n",
    "            \n",
    "            # Original image\n",
    "            img = image.permute(1, 2, 0).cpu().numpy()\n",
    "            img = np.clip(img * np.array([0.229, 0.224, 0.225]) + \n",
    "                          np.array([0.485, 0.456, 0.406]), 0, 1)\n",
    "            \n",
    "            # Plotting\n",
    "            fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
    "            axs[0].imshow(img)\n",
    "            axs[0].set_title(f\"Original Image\\nGlobal Score: {score:.2f}\")\n",
    "            axs[0].axis('off')\n",
    "            \n",
    "            axs[1].imshow(img)\n",
    "            axs[1].imshow(pred_local_norm, alpha=0.6, cmap='jet')\n",
    "            axs[1].set_title(f\"Predicted Quality Heatmap\\nGlobal Score: {pred_global:.2f}\")\n",
    "            axs[1].axis('off')\n",
    "            \n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Quality Maps\n",
    "visualize_quality_maps(model, full_dataset, device, num_samples=3)\n",
    "\n",
    "# Visualize Heatmaps\n",
    "visualize_heatmap(model, full_dataset, device, num_samples=3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
